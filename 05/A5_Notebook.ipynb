{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUFNk0BJAMZH"
   },
   "source": [
    "# Assignment 5: Extended Long Short-Term Memory (xLSTM)\n",
    "\n",
    "*Author:* Philipp Seidl\n",
    "\n",
    "*Copyright statement:* This  material,  no  matter  whether  in  printed  or  electronic  form,  may  be  used  for  personal  and non-commercial educational use only.  Any reproduction of this manuscript, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors.\n",
    "\n",
    "In this assignment, we will explore the xLSTM architecture, a novel extension of the classic LSTM model. The paper can be found here: https://arxiv.org/abs/2405.04517"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBfgx3oEAc3W"
   },
   "source": [
    "## Background\n",
    "Recurrent Neural Networks (RNNs), particularly LSTMs, have proven highly effective in various sequence modeling tasks. However, the emergence of Transformers, with their parallel processing capabilities, has shifted the focus away from LSTMs, especially in large-scale language modeling.\n",
    "The xLSTM architecture aims to bridge this gap by enhancing LSTMs with mechanisms inspired by modern LLMs (e.g. block-strucutre, residual connections, ...).  Further it introduces:\n",
    "- Exponential gating with normalization and stabilization techniques, which improves gradient flow and memory capacity.\n",
    "- Modifications to the LSTM memory structure, resulting in two variants:\n",
    "    - sLSTM: Employs a scalar memory with a scalar update rule and a new memory mixing technique through recurrent connections.\n",
    "    - mLSTM: Features a matrix memory, employs a covariance update rule, and is fully parallelizable, making it suitable for scaling.\n",
    "\n",
    "By integrating these extensions into residual block backbones, xLSTM blocks are formed, which can then be residually stacked to create complete xLSTM architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08ut_E9kAdpU"
   },
   "source": [
    "## Exercise 1: Environment Setup\n",
    "\n",
    "When working with new architectures or specialized frameworks, it's essential to correctly set up the environment to ensure reproducability. This exercise focuses on setting up the environment for working with the `xlstm` repository.\n",
    "\n",
    "1. Visit and clone the official repository: [https://github.com/NX-AI/xlstm](https://github.com/NX-AI/xlstm).  \n",
    "2. Set up the environment  \n",
    "3. Document your setup:  \n",
    "   - OS, Python version, Environment setup, CUDA version (if applicable), and GPU details.  \n",
    "   - Note any challenges you faced and how you resolved them. \n",
    "4. Submit your setup as a bash script using the IPython `%%bash` magic. Ensure it is reproducible.\n",
    "\n",
    "Getting mLSTM working only is fine (if you encounter issues with sLSTM cuda kernels)\n",
    "\n",
    "> **Note**: Depending on your system setup, you may need to adjust the `environment_pt220cu121.yaml` file, such as for the CUDA version. For this assignment, it is recommended to run it on GPUs. If you don't have one, consider using  [Colab](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true) or other online resources.\n",
    "\n",
    "> **Recommendations**: While the repository suggests using `conda`, we recommend using `mamba` or `micromamba` instead (way faster) (except if you are using colab). Learn more about them here: [https://mamba.readthedocs.io/en/latest/index.html](https://mamba.readthedocs.io/en/latest/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Bdb5fIMaKea1",
    "outputId": "fbea5037-812c-41a1-bd42-79f4b9790cd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/NX-AI/xlstm@79e463c84cd8bb839bb9a7d81138f1a0184c68a1\n",
      "  Cloning https://github.com/NX-AI/xlstm (to revision 79e463c84cd8bb839bb9a7d81138f1a0184c68a1) to /private/var/folders/z1/xfwm3xr90019fcl3by7y113c0000gn/T/pip-req-build-en87xn2t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/NX-AI/xlstm /private/var/folders/z1/xfwm3xr90019fcl3by7y113c0000gn/T/pip-req-build-en87xn2t\n",
      "  Running command git rev-parse -q --verify 'sha^79e463c84cd8bb839bb9a7d81138f1a0184c68a1'\n",
      "  Running command git fetch -q https://github.com/NX-AI/xlstm 79e463c84cd8bb839bb9a7d81138f1a0184c68a1\n",
      "  Running command git checkout -q 79e463c84cd8bb839bb9a7d81138f1a0184c68a1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Resolved https://github.com/NX-AI/xlstm to commit 79e463c84cd8bb839bb9a7d81138f1a0184c68a1\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: omegaconf in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from omegaconf) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from omegaconf) (6.0.2)\n",
      "Requirement already satisfied: dacite in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (1.8.1)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "########## SOLUTION BEGIN ##########\n",
    "pip install git+https://github.com/NX-AI/xlstm@79e463c84cd8bb839bb9a7d81138f1a0184c68a1\n",
    "pip install omegaconf\n",
    "pip install dacite\n",
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "4FejZLBoK_Lo",
    "outputId": "37eadcd9-3134-45df-da5c-0db1a267f332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify your installation of xLSTM:\n",
    "from omegaconf import OmegaConf\n",
    "from dacite import from_dict\n",
    "from dacite import Config as DaciteConfig\n",
    "from xlstm import xLSTMBlockStack, xLSTMBlockStackConfig\n",
    "import os\n",
    "import torch\n",
    "import time, math\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "use_slstm_kernels = False # set to True if you want to check if sLSTM cuda kernels are working\n",
    "\n",
    "xlstm_cfg = f\"\"\"\n",
    "mlstm_block:\n",
    "  mlstm:\n",
    "    conv1d_kernel_size: 4\n",
    "    qkv_proj_blocksize: 4\n",
    "    num_heads: 8\n",
    "slstm_block:\n",
    "  slstm:\n",
    "    backend: {'cuda' if use_slstm_kernels else 'vanilla'}\n",
    "    num_heads: 4\n",
    "    conv1d_kernel_size: 4\n",
    "    bias_init: powerlaw_blockdependent\n",
    "  feedforward:\n",
    "    proj_factor: 1.3\n",
    "    act_fn: gelu\n",
    "context_length: 64\n",
    "num_blocks: 7\n",
    "embedding_dim: 64\n",
    "slstm_at: [] # empty = mLSTM only\n",
    "\"\"\"\n",
    "cfg = OmegaConf.create(xlstm_cfg)\n",
    "cfg = from_dict(data_class=xLSTMBlockStackConfig, data=OmegaConf.to_container(cfg), config=DaciteConfig(strict=True))\n",
    "xlstm_stack = xLSTMBlockStack(cfg)\n",
    "\n",
    "x = torch.randn(4, 64, 64).to(DEVICE)\n",
    "xlstm_stack = xlstm_stack.to(DEVICE)\n",
    "y = xlstm_stack(x)\n",
    "y.shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xLSTMBlockStackConfig(mlstm_block=mLSTMBlockConfig(mlstm=mLSTMLayerConfig(proj_factor=2.0, round_proj_up_dim_up=True, round_proj_up_to_multiple_of=64, _proj_up_dim=128, conv1d_kernel_size=4, qkv_proj_blocksize=4, num_heads=8, embedding_dim=64, bias=False, dropout=0.0, context_length=64, _num_blocks=7, _inner_embedding_dim=128), _num_blocks=7, _block_idx=None), slstm_block=sLSTMBlockConfig(slstm=sLSTMLayerConfig(hidden_size=64, num_heads=4, num_states=4, backend='vanilla', function='slstm', bias_init='powerlaw_blockdependent', recurrent_weight_init='zeros', _block_idx=None, _num_blocks=7, num_gates=4, gradient_recurrent_cut=False, gradient_recurrent_clipval=None, forward_clipval=None, batch_size=8, input_shape='BSGNH', internal_input_shape='SBNGH', output_shape='BNSH', constants={}, dtype='bfloat16', dtype_b='float32', dtype_r='bfloat16', dtype_w='bfloat16', dtype_g='bfloat16', dtype_s='bfloat16', dtype_a='float32', enable_automatic_mixed_precision=True, initial_val=0.0, embedding_dim=64, conv1d_kernel_size=4, group_norm_weight=True, dropout=0.0), feedforward=FeedForwardConfig(proj_factor=1.3, round_proj_up_dim_up=True, round_proj_up_to_multiple_of=64, _proj_up_dim=0, act_fn='gelu', embedding_dim=-1, dropout=0.0, bias=False, ff_type='ffn_gated', _num_blocks=1), _num_blocks=7, _block_idx=None), context_length=64, num_blocks=7, embedding_dim=64, add_post_blocks_norm=True, bias=False, dropout=0.0, slstm_at=[], _block_map='0,0,0,0,0,0,0')\n"
     ]
    }
   ],
   "source": [
    "print(xlstm_stack.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbkUQdktAkeG"
   },
   "source": [
    "## Exercise 2: Understanding xLSTM Hyperparameters\n",
    "Explain key hyperparameters that influence the performance and behavior of the xLSTM architecture and explain how they influence total parameter count.\n",
    "The explanation should include: proj_factor, num_heads, act_fn, context_length, num_blocks, embedding_dim, hidden_size, dropout, slstm_at, qkv_proj_blocksize, conv1d_kernel_size. Also include how the matrix memory size of mLSTM is determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SOLUTION BEGIN ##########\n",
    "\n",
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4rSyOdnAv6r"
   },
   "source": [
    "## Exercise 3: Train an xLSTM model on the Trump Dataset from the previous exercise\n",
    "Your task is to train an xLSTM model on the Trump Dataset from the previous exercise. \n",
    "- The goal is to achieve an average validation loss $\\mathcal{L}_{\\text{val}} < 1.35$. \n",
    "- You do not need to perform an extensive hyperparameter search, but you should document your runs. Log your runs with used hyperparameters using tools like wandb, neptune, mlflow, ... or a similar setup. Log training/validation loss and learning rate over steps as well as total trainable parameters of the model for each run.\n",
    "- You can use the training setup from the previous exercises or any setup of your choice using high level training libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeppGPTResidual(torch.nn.Module):\n",
    "    def __init__(self, config, hidden_size = 64, vocab_size = 40):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1 xlstm block\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, hidden_size)\n",
    "        self.xlstm_stack = xLSTMBlockStack(config)\n",
    "        self.proj = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.ln = torch.nn.LayerNorm(hidden_size)\n",
    "\n",
    "        # 2 xlstm blocks\n",
    "        self.xlstm_stack2 = xLSTMBlockStack(config)\n",
    "        self.proj2 = torch.nn.Linear(hidden_size, vocab_size)\n",
    "        self.ln2 = torch.nn.LayerNorm(vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        x = self.xlstm_stack(emb)\n",
    "        x = self.proj(x)\n",
    "        x = self.ln(x) + emb\n",
    "        x = self.xlstm_stack2(x)\n",
    "        x = self.proj2(x)\n",
    "        x = self.ln2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeppGPT(torch.nn.Module):\n",
    "    def __init__(self, config, hidden_size = 64, vocab_size = 40):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, hidden_size)\n",
    "        self.xlstm_stack = xLSTMBlockStack(config)\n",
    "        self.proj = torch.nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        out1 = self.xlstm_stack(emb)\n",
    "        out2 = self.proj(out1)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeppGPT(\n",
      "  (embedding): Embedding(40, 64)\n",
      "  (xlstm_stack): xLSTMBlockStack(\n",
      "    (blocks): ModuleList(\n",
      "      (0-6): 7 x mLSTMBlock(\n",
      "        (xlstm_norm): LayerNorm()\n",
      "        (xlstm): mLSTMLayer(\n",
      "          (proj_up): Linear(in_features=64, out_features=256, bias=False)\n",
      "          (q_proj): LinearHeadwiseExpand(in_features=128, num_heads=32, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
      "          (k_proj): LinearHeadwiseExpand(in_features=128, num_heads=32, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
      "          (v_proj): LinearHeadwiseExpand(in_features=128, num_heads=32, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
      "          (conv1d): CausalConv1d(\n",
      "            (conv): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
      "          )\n",
      "          (conv_act_fn): SiLU()\n",
      "          (mlstm_cell): mLSTMCell(\n",
      "            (igate): Linear(in_features=384, out_features=8, bias=True)\n",
      "            (fgate): Linear(in_features=384, out_features=8, bias=True)\n",
      "            (outnorm): MultiHeadLayerNorm()\n",
      "          )\n",
      "          (ogate_act_fn): SiLU()\n",
      "          (proj_down): Linear(in_features=128, out_features=64, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (post_blocks_norm): LayerNorm()\n",
      "  )\n",
      "  (proj): Linear(in_features=64, out_features=40, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SeppGPT(xlstm_stack.config).to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/3000] loss=3.729189157485962\n",
      "[0/3000] val_loss=3.69344357252121\n",
      "[10/3000] loss=3.6556808948516846\n",
      "[20/3000] loss=3.610262632369995\n",
      "[30/3000] loss=3.4089105129241943\n",
      "[40/3000] loss=3.139468193054199\n",
      "[50/3000] loss=2.8497982025146484\n",
      "[60/3000] loss=2.6778461933135986\n",
      "[70/3000] loss=2.3739306926727295\n",
      "[80/3000] loss=2.2838406562805176\n",
      "[90/3000] loss=2.2506320476531982\n",
      "[100/3000] loss=2.388808012008667\n",
      "[110/3000] loss=2.178525924682617\n",
      "[120/3000] loss=2.1315104961395264\n",
      "[130/3000] loss=2.0674633979797363\n",
      "[140/3000] loss=1.9370713233947754\n",
      "[150/3000] loss=2.032170534133911\n",
      "[160/3000] loss=1.9046087265014648\n",
      "[170/3000] loss=1.809989333152771\n",
      "[180/3000] loss=1.7912341356277466\n",
      "[190/3000] loss=2.0180132389068604\n",
      "[200/3000] loss=1.929832935333252\n",
      "[200/3000] val_loss=2.014889633655548\n",
      "[210/3000] loss=1.8513693809509277\n",
      "[220/3000] loss=1.9059723615646362\n",
      "[230/3000] loss=1.8157931566238403\n",
      "[240/3000] loss=1.958178162574768\n",
      "[250/3000] loss=1.6897996664047241\n",
      "[260/3000] loss=1.6835004091262817\n",
      "[270/3000] loss=1.7912324666976929\n",
      "[280/3000] loss=1.6655522584915161\n",
      "[290/3000] loss=1.7364602088928223\n",
      "[300/3000] loss=1.5906177759170532\n",
      "[310/3000] loss=1.5524448156356812\n",
      "[320/3000] loss=1.5444031953811646\n",
      "[330/3000] loss=1.6175497770309448\n",
      "[340/3000] loss=1.8251031637191772\n",
      "[350/3000] loss=1.686488151550293\n",
      "[360/3000] loss=1.714124321937561\n",
      "[370/3000] loss=1.5388941764831543\n",
      "[380/3000] loss=1.8105181455612183\n",
      "[390/3000] loss=1.6257292032241821\n",
      "[400/3000] loss=1.5181875228881836\n",
      "[400/3000] val_loss=1.8018582046031952\n",
      "[410/3000] loss=1.563144326210022\n",
      "[420/3000] loss=1.476204514503479\n",
      "[430/3000] loss=1.6683861017227173\n",
      "[440/3000] loss=1.6143792867660522\n",
      "[450/3000] loss=1.56714928150177\n",
      "[460/3000] loss=1.5356435775756836\n",
      "[470/3000] loss=1.5208207368850708\n",
      "[480/3000] loss=1.5258744955062866\n",
      "[490/3000] loss=1.6783181428909302\n",
      "[500/3000] loss=1.6151528358459473\n",
      "[510/3000] loss=1.6027005910873413\n",
      "[520/3000] loss=1.410115122795105\n",
      "[530/3000] loss=1.5772275924682617\n",
      "[540/3000] loss=1.4163442850112915\n",
      "[550/3000] loss=1.5074272155761719\n",
      "[560/3000] loss=1.337647795677185\n",
      "[570/3000] loss=1.5488923788070679\n",
      "[580/3000] loss=1.6066627502441406\n",
      "[590/3000] loss=1.505642294883728\n",
      "[600/3000] loss=1.593031406402588\n",
      "[600/3000] val_loss=1.6674964904785157\n",
      "[610/3000] loss=1.4806677103042603\n",
      "[620/3000] loss=1.5386638641357422\n",
      "[630/3000] loss=1.6268657445907593\n",
      "[640/3000] loss=1.6755307912826538\n",
      "[650/3000] loss=1.489876389503479\n",
      "[660/3000] loss=1.5483417510986328\n",
      "[670/3000] loss=1.5132789611816406\n",
      "[680/3000] loss=1.5578206777572632\n",
      "[690/3000] loss=1.5244115591049194\n",
      "[700/3000] loss=1.5616387128829956\n",
      "[710/3000] loss=1.4014145135879517\n",
      "[720/3000] loss=1.4855350255966187\n",
      "[730/3000] loss=1.5838565826416016\n",
      "[740/3000] loss=1.6775380373001099\n",
      "[750/3000] loss=1.5068931579589844\n",
      "[760/3000] loss=1.5286022424697876\n",
      "[770/3000] loss=1.571843147277832\n",
      "[780/3000] loss=1.4684244394302368\n",
      "[790/3000] loss=1.3865365982055664\n",
      "[800/3000] loss=1.4481401443481445\n",
      "[800/3000] val_loss=1.617969846725464\n",
      "[810/3000] loss=1.3505758047103882\n",
      "[820/3000] loss=1.3818026781082153\n",
      "[830/3000] loss=1.5121870040893555\n",
      "[840/3000] loss=1.233242154121399\n",
      "[850/3000] loss=1.405762791633606\n",
      "[860/3000] loss=1.4423370361328125\n",
      "[870/3000] loss=1.7393709421157837\n",
      "[880/3000] loss=1.4252991676330566\n",
      "[890/3000] loss=1.420125961303711\n",
      "[900/3000] loss=1.5048023462295532\n",
      "[910/3000] loss=1.4353561401367188\n",
      "[920/3000] loss=1.5428037643432617\n",
      "[930/3000] loss=1.4403486251831055\n",
      "[940/3000] loss=1.4530149698257446\n",
      "[950/3000] loss=1.315361499786377\n",
      "[960/3000] loss=1.4477120637893677\n",
      "[970/3000] loss=1.2373982667922974\n",
      "[980/3000] loss=1.4041334390640259\n",
      "[990/3000] loss=1.4411805868148804\n",
      "[1000/3000] loss=1.2228468656539917\n",
      "[1000/3000] val_loss=1.546366435289383\n",
      "[1010/3000] loss=1.2948130369186401\n",
      "[1020/3000] loss=1.3681644201278687\n",
      "[1030/3000] loss=1.2140049934387207\n",
      "[1040/3000] loss=1.3160518407821655\n",
      "[1050/3000] loss=1.3564738035202026\n",
      "[1060/3000] loss=1.199316382408142\n",
      "[1070/3000] loss=1.4930013418197632\n",
      "[1080/3000] loss=1.3922113180160522\n",
      "[1090/3000] loss=1.1950621604919434\n",
      "[1100/3000] loss=1.4784387350082397\n",
      "[1110/3000] loss=1.4614909887313843\n",
      "[1120/3000] loss=1.169404149055481\n",
      "[1130/3000] loss=1.4301854372024536\n",
      "[1140/3000] loss=1.2289372682571411\n",
      "[1150/3000] loss=1.3422414064407349\n",
      "[1160/3000] loss=1.343767762184143\n",
      "[1170/3000] loss=1.1099193096160889\n",
      "[1180/3000] loss=1.2454018592834473\n",
      "[1190/3000] loss=1.204262614250183\n",
      "[1200/3000] loss=1.3204736709594727\n",
      "[1200/3000] val_loss=1.4978814482688905\n",
      "[1210/3000] loss=1.3630971908569336\n",
      "[1220/3000] loss=1.4135740995407104\n",
      "[1230/3000] loss=1.5850926637649536\n",
      "[1240/3000] loss=1.5246772766113281\n",
      "[1250/3000] loss=1.276065468788147\n",
      "[1260/3000] loss=1.289862036705017\n",
      "[1270/3000] loss=1.391342043876648\n",
      "[1280/3000] loss=1.3012776374816895\n",
      "[1290/3000] loss=1.2729897499084473\n",
      "[1300/3000] loss=1.3759489059448242\n",
      "[1310/3000] loss=1.2566403150558472\n",
      "[1320/3000] loss=1.309810757637024\n",
      "[1330/3000] loss=1.4257034063339233\n",
      "[1340/3000] loss=1.6591968536376953\n",
      "[1350/3000] loss=1.319507122039795\n",
      "[1360/3000] loss=1.366450309753418\n",
      "[1370/3000] loss=1.2845929861068726\n",
      "[1380/3000] loss=1.1955747604370117\n",
      "[1390/3000] loss=1.2763704061508179\n",
      "[1400/3000] loss=1.2167205810546875\n",
      "[1400/3000] val_loss=1.4980878233909607\n",
      "[1410/3000] loss=1.3490867614746094\n",
      "[1420/3000] loss=1.384926199913025\n",
      "[1430/3000] loss=1.2540465593338013\n",
      "[1440/3000] loss=1.2413655519485474\n",
      "[1450/3000] loss=1.425933837890625\n",
      "[1460/3000] loss=1.420029640197754\n",
      "[1470/3000] loss=1.3138543367385864\n",
      "[1480/3000] loss=1.2448394298553467\n",
      "[1490/3000] loss=1.152230978012085\n",
      "[1500/3000] loss=1.3632301092147827\n",
      "[1510/3000] loss=1.3229564428329468\n",
      "[1520/3000] loss=1.2804429531097412\n",
      "[1530/3000] loss=1.385144591331482\n",
      "[1540/3000] loss=1.3345006704330444\n",
      "[1550/3000] loss=1.3455654382705688\n",
      "[1560/3000] loss=1.256237506866455\n",
      "[1570/3000] loss=1.0489287376403809\n",
      "[1580/3000] loss=1.0855554342269897\n",
      "[1590/3000] loss=1.2988570928573608\n",
      "[1600/3000] loss=1.3776493072509766\n",
      "[1600/3000] val_loss=1.4705488741397859\n",
      "[1610/3000] loss=1.278186559677124\n",
      "[1620/3000] loss=1.1046373844146729\n",
      "[1630/3000] loss=1.3242970705032349\n",
      "[1640/3000] loss=1.2109100818634033\n",
      "[1650/3000] loss=1.329190731048584\n",
      "[1660/3000] loss=1.219232201576233\n",
      "[1670/3000] loss=1.3617342710494995\n",
      "[1680/3000] loss=1.2593756914138794\n",
      "[1690/3000] loss=1.3056821823120117\n",
      "[1700/3000] loss=1.3013242483139038\n",
      "[1710/3000] loss=1.0458365678787231\n",
      "[1720/3000] loss=1.579793095588684\n",
      "[1730/3000] loss=1.2120805978775024\n",
      "[1740/3000] loss=1.2517508268356323\n",
      "[1750/3000] loss=1.2381913661956787\n",
      "[1760/3000] loss=1.2831553220748901\n",
      "[1770/3000] loss=1.3851934671401978\n",
      "[1780/3000] loss=1.366842269897461\n",
      "[1790/3000] loss=1.3544479608535767\n",
      "[1800/3000] loss=1.1197949647903442\n",
      "[1800/3000] val_loss=1.4155589997768403\n",
      "[1810/3000] loss=1.3408904075622559\n",
      "[1820/3000] loss=1.3507176637649536\n",
      "[1830/3000] loss=1.1066973209381104\n",
      "[1840/3000] loss=1.1370902061462402\n",
      "[1850/3000] loss=1.2262519598007202\n",
      "[1860/3000] loss=1.2433876991271973\n",
      "[1870/3000] loss=1.1710755825042725\n",
      "[1880/3000] loss=1.3441904783248901\n",
      "[1890/3000] loss=1.4648876190185547\n",
      "[1900/3000] loss=1.3571432828903198\n",
      "[1910/3000] loss=1.3764818906784058\n",
      "[1920/3000] loss=1.1705456972122192\n",
      "[1930/3000] loss=1.1859335899353027\n",
      "[1940/3000] loss=1.2571276426315308\n",
      "[1950/3000] loss=1.220262050628662\n",
      "[1960/3000] loss=1.2430278062820435\n",
      "[1970/3000] loss=1.219266653060913\n",
      "[1980/3000] loss=1.1243196725845337\n",
      "[1990/3000] loss=1.2595926523208618\n",
      "[2000/3000] loss=1.3833447694778442\n",
      "[2000/3000] val_loss=1.3711345493793488\n",
      "[2010/3000] loss=1.335309386253357\n",
      "[2020/3000] loss=1.0413376092910767\n",
      "[2030/3000] loss=1.2511383295059204\n",
      "[2040/3000] loss=1.321043610572815\n",
      "[2050/3000] loss=1.2410259246826172\n",
      "[2060/3000] loss=1.228096604347229\n",
      "[2070/3000] loss=1.1398669481277466\n",
      "[2080/3000] loss=1.3994437456130981\n",
      "[2090/3000] loss=1.1030362844467163\n",
      "[2100/3000] loss=1.2504647970199585\n",
      "[2110/3000] loss=1.3324719667434692\n",
      "[2120/3000] loss=1.2268122434616089\n",
      "[2130/3000] loss=1.2368947267532349\n",
      "[2140/3000] loss=1.1784462928771973\n",
      "[2150/3000] loss=1.114184856414795\n",
      "[2160/3000] loss=1.3341360092163086\n",
      "[2170/3000] loss=1.2298270463943481\n",
      "[2180/3000] loss=1.2508524656295776\n",
      "[2190/3000] loss=1.1477341651916504\n",
      "[2200/3000] loss=1.1716862916946411\n",
      "[2200/3000] val_loss=1.3832035303115844\n",
      "[2210/3000] loss=1.3046385049819946\n",
      "[2220/3000] loss=1.1242018938064575\n",
      "[2230/3000] loss=1.1192525625228882\n",
      "[2240/3000] loss=1.2631020545959473\n",
      "[2250/3000] loss=1.1938544511795044\n",
      "[2260/3000] loss=1.2962230443954468\n",
      "[2270/3000] loss=1.202876329421997\n",
      "[2280/3000] loss=1.180038332939148\n",
      "[2290/3000] loss=1.1808172464370728\n",
      "[2300/3000] loss=1.183154582977295\n",
      "[2310/3000] loss=1.1739834547042847\n",
      "[2320/3000] loss=1.2154463529586792\n",
      "[2330/3000] loss=1.3211488723754883\n",
      "[2340/3000] loss=1.2322522401809692\n",
      "[2350/3000] loss=1.182130217552185\n",
      "[2360/3000] loss=1.313893437385559\n",
      "[2370/3000] loss=1.1945346593856812\n",
      "[2380/3000] loss=1.077799677848816\n",
      "[2390/3000] loss=1.4982808828353882\n",
      "[2400/3000] loss=1.1626700162887573\n",
      "[2400/3000] val_loss=1.4383601903915406\n",
      "[2410/3000] loss=1.1904906034469604\n",
      "[2420/3000] loss=1.2888076305389404\n",
      "[2430/3000] loss=1.1411930322647095\n",
      "[2440/3000] loss=1.152305006980896\n",
      "[2450/3000] loss=1.1307802200317383\n",
      "[2460/3000] loss=1.1380000114440918\n",
      "[2470/3000] loss=1.3186756372451782\n",
      "[2480/3000] loss=1.0537759065628052\n",
      "[2490/3000] loss=1.3231431245803833\n",
      "[2500/3000] loss=1.3190559148788452\n",
      "[2510/3000] loss=1.1725069284439087\n",
      "[2520/3000] loss=1.0390607118606567\n",
      "[2530/3000] loss=1.155272364616394\n",
      "[2540/3000] loss=1.242385745048523\n",
      "[2550/3000] loss=1.124436855316162\n",
      "[2560/3000] loss=1.178792953491211\n",
      "[2570/3000] loss=1.2954256534576416\n",
      "[2580/3000] loss=1.1992727518081665\n",
      "[2590/3000] loss=1.1575137376785278\n",
      "[2600/3000] loss=1.3388986587524414\n",
      "[2600/3000] val_loss=1.3481934726238252\n",
      "[2610/3000] loss=1.2470349073410034\n",
      "[2620/3000] loss=1.2284481525421143\n",
      "[2630/3000] loss=1.3000903129577637\n",
      "[2640/3000] loss=1.2815347909927368\n",
      "[2650/3000] loss=1.1595734357833862\n",
      "[2660/3000] loss=1.2372452020645142\n",
      "[2670/3000] loss=1.1730512380599976\n",
      "[2680/3000] loss=1.2127695083618164\n",
      "[2690/3000] loss=1.210574746131897\n",
      "[2700/3000] loss=1.1738905906677246\n",
      "[2710/3000] loss=1.2718782424926758\n",
      "[2720/3000] loss=1.2227916717529297\n",
      "[2730/3000] loss=1.1366361379623413\n",
      "[2740/3000] loss=1.128084659576416\n",
      "[2750/3000] loss=1.111854910850525\n",
      "[2760/3000] loss=1.2844916582107544\n",
      "[2770/3000] loss=1.2339146137237549\n",
      "[2780/3000] loss=1.0588291883468628\n",
      "[2790/3000] loss=1.1710987091064453\n",
      "[2800/3000] loss=1.2868572473526\n",
      "[2800/3000] val_loss=1.3697945415973662\n",
      "[2810/3000] loss=1.2371368408203125\n",
      "[2820/3000] loss=1.0804275274276733\n",
      "[2830/3000] loss=1.2869936227798462\n",
      "[2840/3000] loss=1.1103323698043823\n",
      "[2850/3000] loss=1.1116833686828613\n",
      "[2860/3000] loss=1.2409197092056274\n",
      "[2870/3000] loss=1.1038962602615356\n",
      "[2880/3000] loss=1.4063615798950195\n",
      "[2890/3000] loss=1.2097924947738647\n",
      "[2900/3000] loss=1.0876142978668213\n",
      "[2910/3000] loss=1.0937076807022095\n",
      "[2920/3000] loss=1.274557113647461\n",
      "[2930/3000] loss=1.2044259309768677\n",
      "[2940/3000] loss=1.2085977792739868\n",
      "[2950/3000] loss=1.1926525831222534\n",
      "[2960/3000] loss=1.0114974975585938\n",
      "[2970/3000] loss=1.2279835939407349\n",
      "[2980/3000] loss=1.211485505104065\n",
      "[2990/3000] loss=1.2905259132385254\n",
      "training took 179.84194087982178 seconds\n"
     ]
    }
   ],
   "source": [
    "########## SOLUTION BEGIN ##########\n",
    "model = SeppGPT(xlstm_stack.config).to(DEVICE)\n",
    "\n",
    "\n",
    "eval_interval = 200 # validate model every .. iterations\n",
    "log_interval = 10 # log training loss every .. iterations\n",
    "eval_iters = 20 # number of batches for loss estimation\n",
    "gradient_accumulation_steps = 5 # used to simulate larger training batch sizes\n",
    "batch_size = 6 # if gradient_accumulation_steps > 1, this is the micro-batch size\n",
    "context_size = 64 # sequence length\n",
    "vocab = 'abcdefghijklmnopqrstuvwxyz0123456789 .!?' # vocabulary\n",
    "vocab_size = len(vocab) # 40\n",
    "n_layer = 8 # number of layers\n",
    "n_head = 8 # number of attention heads\n",
    "hidden_size = 64 # layer size\n",
    "dropout = 1e-5 # for pretraining 0 is good, for finetuning try 0.1+\n",
    "learning_rate = 1e-3 # max learning rate\n",
    "max_iters = 3000 # total number of training iterations\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9 # for AdamW\n",
    "beta2 = 0.999 # for AdamW\n",
    "grad_clip = 1.0 # clip gradients at this value, or disable with 0.0\n",
    "warmup_iters = 100 # how many steps to warm up for\n",
    "min_lr = 1e-4 # minimum learning rate, usually ~= learning_rate/10\n",
    "\n",
    "# learning rate decay scheduler (cosine with warmup)\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * it / warmup_iters\n",
    "    # 2) if it > max_iters, return min learning rate\n",
    "    if it > max_iters:\n",
    "        return min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_iters) / (max_iters - warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
    "    return min_lr + coeff * (learning_rate - min_lr)\n",
    "\n",
    "def load_data(split):\n",
    "    import re\n",
    "    \n",
    "    with open(f'trump_{split}.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    text = text.lower() # convert to lower case\n",
    "    text = re.sub('[^a-z0-9 .!?]', ' ', text) # replace all unknown chars with ' '\n",
    "    text = re.sub(' +', ' ', text) # reduce multiple blanks to one\n",
    "    text = [vocab.index(t) for t in text]\n",
    "    text = torch.tensor(text, dtype=torch.long, device=DEVICE)\n",
    "    return text\n",
    "    \n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    # Random starting indices (shape: [batch_size])\n",
    "    ix = torch.randint(len(data) - context_size, (batch_size,), device=DEVICE)\n",
    "    # Create a 2D index tensor of shape batch_size X context_size\n",
    "    #  For each element in ix, we want to collect [i, i+1, ..., i+context_size-1].\n",
    "    #  So we broadcast-add a range of length `context_size` to each element of ix.\n",
    "    x_positions = ix.unsqueeze(-1) + torch.arange(context_size, device=DEVICE)\n",
    "    y_positions = x_positions + 1  # Shift by 1\n",
    "    x = data[x_positions]  # batch_size X context_size\n",
    "    y = data[y_positions]  # batch_size X context_size\n",
    "    return x, y\n",
    "\n",
    "# helps estimate an arbitrarily accurate loss over either split using many batches\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    output = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        total_loss = 0.0\n",
    "        for _ in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            out = model(X)\n",
    "            loss = torch.nn.functional.cross_entropy(out.view(-1, vocab_size), Y.view(-1))\n",
    "            total_loss += loss.item()\n",
    "        output[split] = total_loss / eval_iters\n",
    "    model.train()\n",
    "    return output\n",
    "\n",
    "# data, model, optimizer, etc.\n",
    "train_data = load_data('train')\n",
    "val_data = load_data('val')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(beta1, beta2), weight_decay=weight_decay)\n",
    "optimizer.param_groups[0]['lr'] = learning_rate\n",
    "iter_num = 0\n",
    "best_val_loss = 1e9\n",
    "X, Y = get_batch('train') # fetch the very first batch\n",
    "t0 = time.time()\n",
    "embedding = torch.nn.Embedding(vocab_size, hidden_size).to(DEVICE)\n",
    "########## YOUR SOLUTION HERE ##########\n",
    "\n",
    "for iter_num in range(max_iters):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(X)\n",
    "    loss = torch.nn.functional.cross_entropy(out.view(-1, vocab_size), Y.view(-1))\n",
    "    if grad_clip > 0.0:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iter_num % log_interval == 0:\n",
    "        print(f'[{iter_num}/{max_iters}] loss={loss.item()}')\n",
    "    if iter_num % eval_interval == 0:\n",
    "        val_loss = estimate_loss()['val']\n",
    "        print(f'[{iter_num}/{max_iters}] val_loss={val_loss}')\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "    X, Y = get_batch('train')\n",
    "    lr = get_lr(iter_num)\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "print(f'training took {time.time()-t0} seconds')\n",
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVADqjO1A9kI"
   },
   "source": [
    "## Exercise 4: Utilizing a Pretrained Model (Bonus)\n",
    "\n",
    "Foundation Models, those pretrained on large amounts of data are more and more important. We can use those models and fine-tune them on our dataset, rather then training them from scratch.\n",
    "Here are the things to consider:\n",
    "\n",
    "- Model Selection: Choose a pretrained language model from an online repository. Hint: You can explore platforms like Hugging Face (huggingface.co), which host numerous pretrained models.\n",
    "\n",
    "- Dataset: Use the Trump dataset with the same training and validation split as in previous exercises. You do not need to use character tokenization.\n",
    "\n",
    "- Performance Evaluation: Evaluate the performance of the pretrained model on the validation set before and during fine-tuning. Report average-CE-loss as well as an example generated sequence with the same prompt for each epoch.\n",
    " \n",
    "- Fine-tuning: Adjust the learning rate, potentially freeze some layers, train for a few epochs with a framework of your choice (e.g. [lightning](https://lightning.ai/docs/pytorch/stable/), [huggingface](https://huggingface.co/models), ...)\n",
    "\n",
    "- Computational Resources: Be mindful of the computational demands of pretrained models. You might need access to GPUs. Try to keep the model size at a minimum and go for e.g. distilled versions or other small LMs\n",
    "\n",
    "- Hyperparameter Tuning: You can experiment with different learning rates and potentially other hyperparameters during fine-tuning but no need to do this in depth\n",
    "\n",
    "By completing this exercise, you will gain experience with utilizing pretrained models, understanding their capabilities, and the process of fine-tuning. Decreasing the validation loss can be seen a success for this exercise.\n",
    "\n",
    "> **Note**: This is a standalone exercise and doesn't build upon the previous tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (4.47.1)\n",
      "Requirement already satisfied: filelock in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from transformers) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eliasmindlberger/workspace/LSTM/.venv/lib/python3.10/site-packages (from requests->transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "wqv4tH69Ab0X"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:  50%|█████     | 1/2 [00:36<00:36, 36.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/Phi-3-mini-4k-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/Phi-3-mini-4k-instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m########## YOUR SOLUTION HERE ##########\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:559\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    558\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m add_generation_mixin_to_remote_model(model_class)\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:3990\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3987\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   3988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[1;32m   3989\u001b[0m     \u001b[38;5;66;03m# resolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3990\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3997\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3999\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4001\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4002\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4003\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4005\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4006\u001b[0m     is_safetensors_available()\n\u001b[1;32m   4007\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m   4008\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4009\u001b[0m ):\n\u001b[1;32m   4010\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:1098\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshard_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:860\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    842\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    858\u001b[0m     )\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1009\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1007\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1009\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1020\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1543\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1541\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1543\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1552\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1553\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:452\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    450\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    454\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/urllib3/response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1069\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/workspace/LSTM/.venv/lib/python3.10/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########## SOLUTION BEGIN ##########\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True)\n",
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
